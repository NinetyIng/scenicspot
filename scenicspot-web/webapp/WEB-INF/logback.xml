<?xml version="1.0" encoding="UTF-8"?>
<!-- /opt/appl/tomcat/webapps/graphic-route/WEB-INF/classes -->
<!-- scan：当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。 scanPeriod：设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒当scan为true时，此属性生效。默认的时间间隔为1分钟。
debug：当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 -->
<configuration scan="true" scanPeriod="10 seconds" debug="false">
    <!-- 获取时间戳 -->
    <timestamp key="bySecond" datePattern="yyyy-MM-dd'T'HHmmss"/>
    <contextName>${bySecond}</contextName>
    <!-- address performance concern with jul-to-slf4j -->
    <contextListener class="ch.qos.logback.classic.jul.LevelChangePropagator">
        <resetJUL>true</resetJUL>
    </contextListener>
    <!-- To enable JMX Management -->
    <jmxConfigurator/>
    <!-- 定义日志的根目录 .linux应改成全路径 -->
    <property name="LOG_HOME" value="/opt/appl/tomcat/logs/graphic-route"/>
<!--     <property name="LOG_HOME" value="D:/program/development/apache-tomcat-8.5.16/logs/mcht_token"/> -->
    <!-- 定义日志文件名称 -->
    <property name="log.app" value="${LOG_HOME}/app"/>
    <!-- 定义access监控日志 -->
    <property name="log.access" value="${LOG_HOME}/access"/>
    <!-- interface日志 -->
    <property name="log.interface" value="${LOG_HOME}/interface"/>
    <!-- error级别日志 -->
    <property name="log.error" value="${LOG_HOME}/error"/>
    <!-- remote日志 -->
    <property name="log.remote" value="${LOG_HOME}/remote"/>
    <!-- druid日志 -->
    <property name="log.druid" value="${LOG_HOME}/druid"/>
    <!-- sql日志 -->
    <property name="log.sql" value="${LOG_HOME}/sql" />

    <!-- 单个压缩文件最大大小 -->
    <property name="log.maxFileSize" value="10MB"/>
    <!-- 日志保存60天 -->
    <property name="log.maxHistory" value="60"/>
    <!-- 压缩文件总共大小最大30GB -->
    <property name="log.totalSizeCap" value="30GB"/>
    
    <!-- ch.qos.logback.core.ConsoleAppender 表示控制台输出 -->
    <appender name="stdout" class="ch.qos.logback.core.ConsoleAppender">
        <!-- 日志输出格式：%d表示日期时间，%thread表示线程名，%-5level：级别从左显示5个字符宽度 %logger{80} 表示logger名字最长80个字符，否则按照句点分割。
        %msg：日志消息，%n是换行符 -->
        <layout class="ch.qos.logback.classic.PatternLayout">
            <pattern>[%date{yyyy-MM-dd HH:mm:ss}] [%thread] %-5level [%logger] [%X{transactionId}] - %msg%n</pattern>
        </layout>
    </appender>
   <!-- 滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将日志记录到其他文件 -->
    <appender name="appLogAppender"
              class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!-- 过滤掉 TRACE 和 DEBUG 级别的日志-->
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>INFO</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <!-- 当发生滚动时，决定 RollingFileAppender 的行为，涉及文件移动和重命名 TimeBasedRollingPolicy： 最常用的滚动策略，它根据时间来制定滚动策略，既负责滚动也负责出发滚动。 -->
        <File>${log.app}/app.log</File>
        <!--如果是 true，⽇志被追加到⽂件结尾，如果是 false，清空现存⽂件 -->
        <append>true</append>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- 滚动时产生的文件的存放位置及文件名称 %d{yyyy-MM-dd}：按天进行日志滚动 %i：当文件大小超过maxFileSize时，按照i进行文件滚动 -->
            <fileNamePattern>
                ${log.app}/app.log.%d{yyyy-MM-dd-HH}.%i
            </fileNamePattern>
            <!-- 可选节点，控制保留的归档文件的最大数量，超出数量就删除旧文件。假设设置每天滚动， 且maxHistory是60，则只保存最近60天的文件，删除之前的旧文件。注意，删除旧文件是， 那些为了归档而创建的目录也会被删除。 -->
            <MaxHistory>${log.maxHistory}</MaxHistory>
            <!-- 当日志文件超过maxFileSize指定的大小是，根据上面提到的%i进行日志文件滚动 注意此处配置SizeBasedTriggeringPolicy是无法实现按文件大小进行滚动的，必须配置timeBasedFileNamingAndTriggeringPolicy -->
            <timeBasedFileNamingAndTriggeringPolicy
                    class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <maxFileSize>${log.maxFileSize}</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
        </rollingPolicy>
        <!-- 日志输出格式：%d表示日期时间，%thread表示线程名，%-5level：级别从左显示5个字符宽度 %logger{80} 表示logger名字最长80个字符，否则按照句点分割。 %msg：日志消息，%n是换行符 -->
        <encoder>
            <Pattern>[%date{yyyy-MM-dd HH:mm:ss}] [%thread] %-5level [%logger] [%X{transactionId}] - %replace(%msg){'\"password\"\:\"\w+\"', '\"password\"\:\"\*\*\*\"'}%n</Pattern>
            <charset>UTF-8</charset>
        </encoder>
       <!--
         <layout class="ch.qos.logback.classic.PatternLayout">
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [ %thread ] - [ %-5level ] [%logger{80} : %line ] - %msg%n
            </pattern>
        </layout> 
        -->
    </appender>
    <!-- 运维监控的日志 -->
    <appender name="access"
              class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!-- 过滤掉 TRACE 和 DEBUG 级别的日志-->
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>INFO</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <File>${log.access}/access.log</File>
        <!--如果是 true，⽇志被追加到⽂件结尾，如果是 false，清空现存⽂件 -->
        <append>true</append>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>
                ${log.access}/access.log.%d{yyyy-MM-dd-HH}.%i
            </fileNamePattern>
            <!-- 可选节点，控制保留的归档文件的最大数量，超出数量就删除旧文件。假设设置每天滚动， 且maxHistory是60，则只保存最近60天的文件，删除之前的旧文件。注意，删除旧文件是，那些为了归档而创建的目录也会被删除。 -->
            <MaxHistory>${log.maxHistory}</MaxHistory>
            <timeBasedFileNamingAndTriggeringPolicy
                    class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <MaxFileSize>${log.maxFileSize}</MaxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
        </rollingPolicy>
        <!-- 日志输出格式：%d表示日期时间，%thread表示线程名，%-5level：级别从左显示5个字符宽度 %logger{80} 表示logger名字最长80个字符，否则按照句点分割。%msg：日志消息，%n是换行符 -->  
         <encoder>
            <Pattern>%msg%n</Pattern>
            <charset>UTF-8</charset>
        </encoder>
        
    </appender>
    <!--接口日志打印，该服务本身被请求的内部接口 -->
    <appender name="interface"
              class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!-- 过滤掉 TRACE 和 DEBUG 级别的日志-->
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>INFO</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <File>${log.interface}/interface.log</File>
        <!--如果是 true，⽇志被追加到⽂件结尾，如果是 false，清空现存⽂件 -->
        <append>true</append>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>
                ${log.interface}/interface.log.%d{yyyy-MM-dd-HH}.%i
            </fileNamePattern>
            <!-- 可选节点，控制保留的归档文件的最大数量，超出数量就删除旧文件。假设设置每天滚动， 且maxHistory是60，则只保存最近60天的文件，删除之前的旧文件。注意，删除旧文件是，那些为了归档而创建的目录也会被删除。 -->
            <MaxHistory>${log.maxHistory}</MaxHistory>
            <timeBasedFileNamingAndTriggeringPolicy
                    class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <MaxFileSize>${log.maxFileSize}</MaxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
        </rollingPolicy>
        <!-- 日志输出格式：%d表示日期时间，%thread表示线程名，%-5level：级别从左显示5个字符宽度 %logger{80} 表示logger名字最长80个字符，否则按照句点分割。%msg：日志消息，%n是换行符 -->
        <encoder>
            <Pattern>[%date{yyyy-MM-dd HH:mm:ss}] [%thread] %-5level [%logger] [%X{transactionId}] - %replace(%msg){'\"password\"\:\"\w+\"', '\"password\"\:\"\*\*\*\"'}%n</Pattern>
            <charset>UTF-8</charset>
        </encoder>
        
    </appender>
    <!--错误日志，包括业务错误日志、系统错误日志，是所有错误日志的汇总 -->
    <appender name="errorlog"
              class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!-- 时间滚动输出 level为 ERROR 日志 -->
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>ERROR</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <File>${log.error}/error.log</File>
        <!-- 如果是 true，⽇志被追加到⽂件结尾，如果是 false，清空现存⽂件 -->
        <append>true</append>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>
                ${log.error}/error.log.%d{yyyy-MM-dd-HH}-%i
            </fileNamePattern>
            <!-- 可选节点，控制保留的归档文件的最大数量，超出数量就删除旧文件。假设设置每天滚动， 且maxHistory是60，则只保存最近60天的文件，删除之前的旧文件。注意，删除旧文件是，那些为了归档而创建的目录也会被删除。 -->
            <MaxHistory>${log.maxHistory}</MaxHistory>
            <timeBasedFileNamingAndTriggeringPolicy
                    class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <MaxFileSize>${log.maxFileSize}</MaxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
        </rollingPolicy>
        <!-- 日志输出格式：%d表示日期时间，%thread表示线程名，%-5level：级别从左显示5个字符宽度 %logger{80} 表示logger名字最长80个字符，否则按照句点分割。%msg：日志消息，%n是换行符 -->
        <encoder>
            <Pattern>[%date{yyyy-MM-dd HH:mm:ss}] [%thread] %-5level [%logger] [%X{transactionId}] - %msg%n</Pattern>
            <charset>UTF-8</charset>
        </encoder>
        
    </appender>
    <!--第三方接口日志，调用第三方接口服务（dubbo、webservice） -->
    <appender name="remote"
              class="ch.qos.logback.core.rolling.RollingFileAppender">
        <!-- 过滤掉 TRACE 和 DEBUG级别的日志-->
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>INFO</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <File>${log.remote}/remote.log</File>
        <append>true</append>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>
                ${log.remote}/remote.log.%d{yyyy-MM-dd-HH}.%i
            </fileNamePattern>
            <!-- 可选节点，控制保留的归档文件的最大数量，超出数量就删除旧文件。假设设置每天滚动， 且maxHistory是60，则只保存最近60天的文件，删除之前的旧文件。注意，删除旧文件是，那些为了归档而创建的目录也会被删除。 -->
            <MaxHistory>${log.maxHistory}</MaxHistory>
            <timeBasedFileNamingAndTriggeringPolicy
                    class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <MaxFileSize>${log.maxFileSize}</MaxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
        </rollingPolicy>
        <!-- 日志输出格式：%d表示日期时间，%thread表示线程名，%-5level：级别从左显示5个字符宽度 %logger{80} 表示logger名字最长80个字符，否则按照句点分割。 %msg：日志消息，%n是换行符 -->
        <encoder>
            <Pattern>[%date{yyyy-MM-dd HH:mm:ss}] [%thread] %-5level [%logger] [%X{transactionId}] - %replace(%msg){'\"password\"\:\"\w+\"', '\"password\"\:\"\*\*\*\"'}%n</Pattern>
            <charset>UTF-8</charset>
        </encoder>
        
    </appender>
    
        <!-- sql日志打印 -->
	<appender name="SQL_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
	
		<File>${log.sql}/sql.log</File>
		<rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
			<!-- 把按大小日期分割出来的文件压缩成zip格式 -->
			<fileNamePattern>${log.sql}/sql.%d{yyyy-MM-dd-HH}.%i.log.zip</fileNamePattern>
			<maxFileSize>${log.maxFileSize}</maxFileSize>
			<maxHistory>${log.maxHistory}</maxHistory>
			<totalSizeCap>${log.totalSizeCap}</totalSizeCap>
		</rollingPolicy>
		<encoder>
            <Pattern>[%date{yyyy-MM-dd HH:mm:ss}] [%thread] %-5level [%logger] [%X{transactionId}] - %msg%n</Pattern>
            <charset>UTF-8</charset>
		</encoder>
	</appender>

    <!--druid log configure -->
    <appender name="Druid"
              class="ch.qos.logback.core.rolling.RollingFileAppender">
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>ERROR</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <File>${log.druid}/druid.log</File>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>
                ${log.druid}/druid.log.%d{yyyy-MM-dd-HH}.%i
            </fileNamePattern>
            <!-- 可选节点，控制保留的归档文件的最大数量，超出数量就删除旧文件。假设设置每天滚动， 且maxHistory是60，则只保存最近60天的文件，删除之前的旧文件。注意，删除旧文件是，那些为了归档而创建的目录也会被删除。 -->
            <MaxHistory>${log.maxHistory}</MaxHistory>
            <timeBasedFileNamingAndTriggeringPolicy
                    class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <MaxFileSize>${log.maxFileSize}</MaxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
        </rollingPolicy>
        <!-- 日志输出格式：%d表示日期时间，%thread表示线程名，%-5level：级别从左显示5个字符宽度 %logger{80} 表示logger名字最长80个字符，否则按照句点分割。
        %msg：日志消息，%n是换行符 -->
        <encoder>
            <Pattern>[%date{yyyy-MM-dd HH:mm:ss}] [%thread] %-5level [%logger] [%X{transactionId}] - %msg%n</Pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>

    
    <!--myibatis log configure -->
    <logger name="com.apache.ibatis" level="DEBUG">
   		<appender-ref ref="SQL_FILE" />
    </logger>
    <logger name="java.sql.Connection" level="DEBUG">
    	<appender-ref ref="SQL_FILE" />
    </logger>
    <logger name="java.sql.Statement" level="DEBUG">
    	<appender-ref ref="SQL_FILE" />
    </logger>
    <logger name="java.sql.PreparedStatement" level="DEBUG">
    	<appender-ref ref="SQL_FILE" />
    </logger>

    <!-- 临时加上-->
    <logger name="com.iboxpay.route.data.mapper" level="DEBUG"/>

    <logger name="com.alibaba.druid">
        <appender-ref ref="Druid"/>
    </logger>

     <!--  dubbo provider api interface log -->
    <logger name="dubbo.interfaceLog" >
        <appender-ref ref="interface"/>
    </logger>
    
     <!--  dubbo comsumer api interface log -->
     <logger name="client-interface">
        <appender-ref ref="interface"/>
        <appender-ref ref="remote"/>
    </logger>

     <!--  dubbo provider api access log -->
    <logger name="provider-access" additivity="false">
        <appender-ref ref="access"/>
    </logger>
    
     <!--  dubbo comsumer api access log -->
    <logger name="client-access" additivity="false">
        <appender-ref ref="access"/>
    </logger>
    
     <!--  http api start -->
    <logger name="http.interfaceLog" >
        <appender-ref ref="interface"/>
    </logger>
    
    <logger name="http.accessLog" additivity="false">
        <appender-ref ref="access"/>
    </logger>

	<!--  http api end -->

    <!-- root与logger是父子关系，没有特别定义则默认为root，任何一个类只会和一个logger对应， 要么是定义的logger，要么是root，判断的关键在于找到这个logger，然后判断这个logger的appender和level。 -->

    <root level="info">
        <appender-ref ref="appLogAppender" />
        <appender-ref ref="errorlog" />
         <appender-ref ref="stdout"/>
    </root>
</configuration>